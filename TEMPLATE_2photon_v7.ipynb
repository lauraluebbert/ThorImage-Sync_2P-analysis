{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7sjWI4p4XwJ"
   },
   "source": [
    "# 2 photon stimulation analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHy9_zY_4XwK"
   },
   "source": [
    "1. Define the path to the folders containing the data below. \n",
    "2. DO NOT CLICK \"RUN ALL\". Run each cell (by clicking \"shift+enter\") until you hit a \"STOP\" cell.\n",
    "    - First STOP cell: Check whether there is a tail in the Thorsync frames (code will plot frames over time below), and define tail clean-up accordingly. Then continue running the notebook until the next STOP cell.\n",
    "    - Subsequent STOP cells: Draw the ROIs (and later the background areas to normalize against), then continue running the notebook. \n",
    "\n",
    "Written by Laura Luebbert  \n",
    "Last updated: Feb 28 17:38:52 PST 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOVwOJ8g4XwL"
   },
   "source": [
    "### Define the directory containing the tif files (saved by ThorImage software):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vokUDPYx4XwM"
   },
   "outputs": [],
   "source": [
    "data_dir =  \"path/to/thorimage_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the directory containing the sync files (saved by ThorSync software):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_dir = \"path/to/sync_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define directory for pickled dictionary and csv file to be saved to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_dir = \"path/to/output_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start running the notebook until you find a \"STOP\" cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFxgogU24Xwc"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dd1P8Vtx4Xwd"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XpYgO2gm4Xwd"
   },
   "outputs": [],
   "source": [
    "# %load_ext blackcellmagic\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJn9ojH_4Xwh"
   },
   "outputs": [],
   "source": [
    "# Tools to read in the image files and filenames\n",
    "import glob\n",
    "import os\n",
    "import re \n",
    "\n",
    "# Calculation and data frame tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing tools\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "\n",
    "import bebi103\n",
    "\n",
    "# Tools to create new folders\n",
    "from pathlib import Path\n",
    "\n",
    "# Tools to save dictionaries\n",
    "import pickle\n",
    "\n",
    "# To make a copy of a dictionary\n",
    "import copy\n",
    "\n",
    "# Load hdf5 and xml files into Python\n",
    "import h5py\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import bokeh\n",
    "import bokeh_catplot\n",
    "from bokeh.plotting import output_file, save\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8rTziXA4Xwj"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5PnrQya4Xwn"
   },
   "source": [
    "# Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9Ofpb_q4Xwn"
   },
   "outputs": [],
   "source": [
    "# Glob string for images (loads all .tif files)\n",
    "im_glob = os.path.join(data_dir, \"Chan*.tif\")\n",
    "im_glob_preview = os.path.join(data_dir, \"*_Preview.tif\")\n",
    "im_glob_chanB = os.path.join(data_dir, \"ChanB_*.tif\")\n",
    "\n",
    "# Get list of tif files in data directory (except for the \"Preview\" tif files and Channel B files - for now)\n",
    "im_list = sorted([i for i in glob.glob(im_glob) if i not in glob.glob(im_glob_preview) and i not in glob.glob(im_glob_chanB)])\n",
    "\n",
    "# Let's look at the first 10 entries\n",
    "im_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GKeYPuIg4Xwp"
   },
   "source": [
    "Create a nested dictionary with information about each sample coupled to the z-stack image matrix, as well as space for matrices added later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvCp77kI4Xwp"
   },
   "outputs": [],
   "source": [
    "dicts = {}\n",
    "\n",
    "for i in range(len(im_list)):\n",
    "    # Get channel\n",
    "    channel = im_list[i].split(\"/\")[-1].split(\"_\")[0]\n",
    "    \n",
    "    # Make sure we do not overwrite a previous dictionary entry    \n",
    "    if dicts.get(channel) == None:\n",
    "        dicts[channel] = {}\n",
    "    \n",
    "    # Get sample number\n",
    "    sample = \"_\".join(im_list[i].split(\"/\")[-1].split(\"_\")[1:-1])\n",
    "    \n",
    "    # Make sure we do not overwrite a previous dictionary entry\n",
    "    if dicts.get(channel, {}).get(sample) == None:\n",
    "        \n",
    "        dicts[channel][sample] = {        \n",
    "            \"matrix_orig\": [],       # Original image z-stack matrices\n",
    "            \"df-f0\": [],             # Image z-stack matrices showinf df/f0 for each pixel\n",
    "            \"f0_matrix\": [],         # Matrix with f0 value of each individual pixel\n",
    "            \"matrix_sum\": [],        # Image matrix of sum projection image \n",
    "            \"df-f0_sum\": [],         # df/f0 of each pixel in sum projection\n",
    "            \"filename\": [],          # What the max projection will be named when saved locally\n",
    "            \"time_points\": [],       # time points in seconds based on fps (counting up from 0)\n",
    "            \"clicks\": [],            # The coordinates of \"clicks\" defining the ROI \n",
    "            \"rois\": [],              # ROI clicks converted to an ROI (polygon) \n",
    "            \"roi_mask\": [],          # Boolean matrix (mask) in the size of my original image with \"True\" values where the ROI is\n",
    "            \"clicks_bkg\": [],        # The coordinates of \"clicks\" defining the background area to normalize against \n",
    "            \"rois_bkg\": [],          # bkg area clicks converted to a polygon\n",
    "            \"mean_int\": [],          # Mean pixel value in ROI (not normalized)\n",
    "            \"mean_int_bkg\": [],      # Mean pixel value in bkg area\n",
    "            \"mean_int_norm\":[],      # Mean pixel value in ROI - mean pixel value in bkg area\n",
    "#             \"median_int\": [],        # Median pixel value in ROI\n",
    "#             \"median_int_bkg\": [],    # Median pixel value in bkg area\n",
    "#             \"median_int_norm\": [],   # Median pixel value in ROI - median pixel value in bkg area\n",
    "#             \"raw_int_den\": [],       # Raw integrated density of ROI (sum of all bkg normalized pixel values inside the ROI) \n",
    "#             \"int_den\": [],           # Integrated density of ROI (product of ROI area and mean bkg normalized pixel value inside the ROI)\n",
    "#             \"mean_fold_change\": [],  # (Mean pixel value of ROI (not normalized) - Mean bkg pixel value) / Mean bkg pixel value\n",
    "#             \"median_fold_change\": [] # (Median pixel value of ROI (not normalized) - Median bkg pixel value) / Median bkg pixel value\n",
    "            }\n",
    "\n",
    "    # Append original image matrices that belong together to form a z-stack\n",
    "    dicts[channel][sample][\"matrix_orig\"].append(skimage.io.imread(im_list[i],is_ome=False))\n",
    "    \n",
    "    # Populate dictionary with original filename (without information automatically added by microscope)\n",
    "    dicts[channel][sample][\"filename\"] = channel + \"_\" + sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract stimulation data from experiment files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sample rate from xml file in sync folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glob string for xml file in sync folder (loads only ThorRealTimeDataSettings file)\n",
    "rtd_glob = os.path.join(sync_dir, \"ThorRealTimeDataSettings.xml\")\n",
    "\n",
    "rtd_file = glob.glob(rtd_glob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to extract sample rate from ThorRealTimeDataSettings.xml file (written by Peter Weir):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_rate(inFileName):\n",
    "    \"\"\"Finds sample rate for a ThorSync .xml file\n",
    "    usage:\n",
    "    sampleRateHz = parse_thor_xml.get_sample_rate(inFileName)\n",
    "\n",
    "    PTW 2015-08-07\"\"\"\n",
    "    tree = ET.parse(inFileName)\n",
    "    root = tree.getroot()\n",
    "    for child in root:\n",
    "        if child.tag == 'DaqDevices':\n",
    "            for grandchild in child:\n",
    "                if grandchild.tag == 'AcquireBoard' and grandchild.attrib['active'] == '1':\n",
    "                    for greatgrandchild in grandchild:\n",
    "                        if greatgrandchild.tag == 'SampleRate' and greatgrandchild.attrib['enable'] == '1':\n",
    "                            sampleRateHz = float(greatgrandchild.attrib['rate'])\n",
    "                            break\n",
    "\n",
    "    return sampleRateHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRateHz = get_sample_rate(rtd_file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRateHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get hdf5 file from sync folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glob string for hdf5 files in sync folder (loads only Episode001 file)\n",
    "sync_glob = os.path.join(sync_dir, \"Episode001.h5\")\n",
    "\n",
    "sync_file = glob.glob(sync_glob)\n",
    "sync_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync = h5py.File(sync_file[0], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hdf5 files behave like dictionaries. List the keys in this hdf5 file:\n",
    "list(sync.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List keys inside \"DI\"\n",
    "list(sync['DI'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract FrameOut to find time axis in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = sync['DI']['FrameOut'][:].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute time in seconds from \"dirty\" frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSec = np.arange(len(frames))/sampleRateHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot frames over time before cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = timeSec\n",
    "y = frames\n",
    "\n",
    "color = \"black\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "plt.plot(x, y, c=color)\n",
    "\n",
    "# Define figure title\n",
    "ax.set_title('Frames over time', weight='bold', size=17)\n",
    "\n",
    "# Set axis labels\n",
    "fontsize = 13\n",
    "fontweight = 'normal'\n",
    "fontproperties = {'weight':fontweight, 'size':fontsize}\n",
    "ax.set_xlabel('Time (s)', fontproperties)\n",
    "ax.set_ylabel('FrameOut', fontproperties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP - Based on the graph above, define whether or not there is a start and end tail of 0s frames in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define whether or not there is a tail\n",
    "start_tail = True\n",
    "end_tail = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up frames by removing 0s at the start and end of the recording if there is a tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_tail == True:\n",
    "    # Find first occurence of non-zero number in frames\n",
    "    for i, value in enumerate(frames):\n",
    "        if (value != 0):\n",
    "            start_idx = i\n",
    "            break\n",
    "else:\n",
    "    # If not tail at start, use first index so nothing is removed from start\n",
    "    start_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if end_tail == True:        \n",
    "    # Same on reversed array to find first occurence of non-zero number from end         \n",
    "    for i, value in enumerate(frames[::-1]):\n",
    "        if (value != 0):\n",
    "            end_idx = i\n",
    "            break\n",
    "        \n",
    "else:\n",
    "    # If not tail at end, set to 1 (will be -1) so nothing is removed from end\n",
    "    end_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice out 0s at beginning and end\n",
    "frames = frames[start_idx:-end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute time in seconds from clean frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSec = np.arange(len(frames))/sampleRateHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot frames over time after cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = timeSec\n",
    "y = frames\n",
    "\n",
    "color = \"black\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "plt.plot(x, y, c=color)\n",
    "\n",
    "# Define figure title\n",
    "ax.set_title('Frames over time after tail cleanup', weight='bold', size=17)\n",
    "\n",
    "# Set axis labels\n",
    "fontsize = 13\n",
    "fontweight = 'normal'\n",
    "fontproperties = {'weight':fontweight, 'size':fontsize}\n",
    "ax.set_xlabel('Time (s)', fontproperties)\n",
    "ax.set_ylabel('FrameOut', fontproperties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract BleachOut channel data (channel used to save LED stimulus):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "led = sync['DI']['SignalGenerator'][:].squeeze()\n",
    "# Slice out parts without frames\n",
    "led = led[start_idx:-end_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot LED stimulation trace over time (in seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = timeSec\n",
    "y = led\n",
    "\n",
    "color = \"black\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "plt.plot(x, y, c=color)\n",
    "\n",
    "# Define figure title\n",
    "ax.set_title('LED stimulation trace', weight='bold', size=17)\n",
    "\n",
    "# Set axis labels\n",
    "fontsize = 13\n",
    "fontweight = 'normal'\n",
    "fontproperties = {'weight':fontweight, 'size':fontsize}\n",
    "ax.set_xlabel('Time (s)', fontproperties)\n",
    "ax.set_ylabel('LED', fontproperties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find time points where the LED turned on and off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert unsigned interger lists to signed\n",
    "# !!! Delete this cell for use with HQ!\n",
    "led = led.astype(int)\n",
    "timeSec = timeSec.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time points when the next minus the previous value is > or < 0, and append to led_on and led_off, respectively\n",
    "led_on = []\n",
    "led_off = []\n",
    "\n",
    "for idx, value in enumerate(led[:-1]):\n",
    "    if led[idx+1] - value > 0:\n",
    "        led_on.append(timeSec[idx])\n",
    "        \n",
    "    if led[idx+1] - value < 0:\n",
    "        led_off.append(timeSec[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "led_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "led_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate frame rate (by dividing the number of frames in the last saved sample by duration of the sync file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = len(dicts[channel][sample][\"matrix_orig\"])/timeSec.max()\n",
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        # Populate dictionary with time points\n",
    "        t = np.arange(len(imagedata[\"matrix_orig\"])) / fps\n",
    "\n",
    "        imagedata[\"time_points\"] = t    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Compute Sum projection for ROI drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sum of frames for each image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        # Convert dict entry to array\n",
    "        image = np.array(imagedata[\"matrix_orig\"])\n",
    "\n",
    "        # Sum z-project using numpy by definining the axis over which to sum the elements.\n",
    "        summed_image = image.sum(axis=0)\n",
    "\n",
    "        # Linearly scale down to 16-bit.\n",
    "        summed_image = (summed_image/summed_image.max())*65535\n",
    "\n",
    "        # Save summed image to dictionary\n",
    "        imagedata[\"matrix_sum\"] = summed_image\n",
    "        \n",
    "        # Save sum projections\n",
    "        skimage.io.imsave(\n",
    "            \"{}/{}_sum_projection_{}.png\".format(saving_dir, data_dir.split(\"/\")[-1], imagedata[\"filename\"]),\n",
    "            summed_image,\n",
    "            plugin=None,\n",
    "            check_contrast=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase contrast, adjust the minimum and maximum intensity values of the displayed image. E.g. to increase brightness, lower the maximum intensity value (max_int_value) by defining a number or by dividing the 'dicts[\"ChanA\"][\"001_001_001\"][\"matrix_sum\"].max()' value by 2, or 3, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define min and max intensity for image display\n",
    "min_int_value = 0\n",
    "max_int_value = dicts[\"ChanA\"][\"001_001_001\"][\"matrix_sum\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        # Enhance contrast using skimage.exposure.rescale_intensity function to define the min and max intensity values\n",
    "        image = skimage.exposure.rescale_intensity(imagedata[\"matrix_sum\"], in_range=(min_int_value, max_int_value))\n",
    "        temp = bebi103.image.record_clicks(\n",
    "            image,\n",
    "            frame_height=800,\n",
    "            title=imagedata[\"filename\"],\n",
    "            flip=False\n",
    "        )\n",
    "        # Save clicks to dictionary\n",
    "        imagedata[\"clicks\"] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert clicks to a tidy data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_for_polygon = []\n",
    "\n",
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        temp = imagedata[\"clicks\"].to_df()\n",
    "\n",
    "        # Add \"roi\" column (in this case there is just one ROI per sample with number \"0\")\n",
    "        temp[\"roi\"] = 0\n",
    "\n",
    "        # Save clicks to dictionary as tidy data frame (this will overwrite the previously saved version of the clicks!)\n",
    "        imagedata[\"clicks\"] = temp\n",
    "        \n",
    "        # Save temp for plotting of ROI in heatmap animation\n",
    "        rois_for_polygon.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the bebi103.image.verts_to_roi function to convert the set of vertices (clicks) that define a polygon to a region of interest (the inside of the polygon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        imagedata[\"rois\"] = [bebi103.image.verts_to_roi(imagedata[\"clicks\"][['x', 'y']].values, \n",
    "                                    imagedata[\"matrix_sum\"].shape[0], \n",
    "                                    imagedata[\"matrix_sum\"].shape[1])\n",
    "        for _, g in imagedata[\"clicks\"].groupby('roi')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the ROIs are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        # The function above returned 3 representations of our ROI:\n",
    "        # roi = Boolean matrix (mask) in the size of my original image with \"True\" values where the ROI is\n",
    "        # roi_bbox = Bounding box around ROI\n",
    "        # roi_box = Boolean matrix in the size of the bounding box (roi_bbox) with \"True\" values where the ROI is\n",
    "        roi, roi_bbox, roi_box = imagedata[\"rois\"][0]\n",
    "        \n",
    "        imagedata[\"roi_mask\"] = roi\n",
    "\n",
    "        # Make grayscale image that is now RGB/CMY\n",
    "        im = np.dstack(3 * [skimage.img_as_float(imagedata[\"matrix_sum\"])])\n",
    "\n",
    "        # Max out first channel\n",
    "        im[roi, 0] = im.max()\n",
    "        plots.append(\n",
    "            bebi103.image.imshow(\n",
    "                im,\n",
    "                title=\"{}_roi\".format(imagedata[\"filename\"]),\n",
    "                frame_height=250,\n",
    "                cmap=\"rgb\",\n",
    "                flip=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Look at the images\n",
    "bokeh.io.show(bokeh.layouts.gridplot(plots, ncols=3))\n",
    "\n",
    "# Save images\n",
    "for idx, plot in enumerate(plots):\n",
    "    bokeh.io.export_png(plot, \n",
    "               filename=\"{}/{}_rois_{}.png\".format(saving_dir, data_dir.split(\"/\")[-1], idx),\n",
    "               width=25000, height=25000)\n",
    "#     export_svgs(plot, \n",
    "#                 filename=\"{}/{}_rois_{}.svg\".format(saving_dir, data_dir.split(\"/\")[-1], idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean and median fluorescence value in ROI (not normalized against bkg):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        \n",
    "        roi, roi_bbox, roi_box = imagedata[\"rois\"][0]\n",
    "        im = imagedata[\"matrix_orig\"]\n",
    "        \n",
    "        for stack in im:\n",
    "            # Calculate mean and median intensity inside ROI for each individual stack\n",
    "            mean_int = stack[roi].mean()\n",
    "#             median_int = np.median(stack[roi])\n",
    "\n",
    "            # Append to dictionary\n",
    "            imagedata[\"mean_int\"].append(mean_int)\n",
    "#             imagedata[\"median_int\"].append(median_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define background area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small square outside of the ROI which is representative of the background fluorescence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase contrast, adjust the minimum and maximum intensity values of the displayed image. E.g. to increase brightness, lower the maximum intensity value (max_int_value) by defining a number or by dividing the 'dicts[\"ChanA\"][\"001_001_001\"][\"matrix_sum\"].max()' value by 2, or 3, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define min and max intensity for image display\n",
    "min_int_value = 0\n",
    "max_int_value = dicts[\"ChanA\"][\"001_001_001\"][\"matrix_sum\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        # Enhance contrast using skimage.exposure.rescale_intensity function to define the min and max intensity values\n",
    "        image = skimage.exposure.rescale_intensity(imagedata[\"matrix_sum\"], in_range=(min_int_value, max_int_value))\n",
    "        temp = bebi103.image.record_clicks(\n",
    "            image,\n",
    "            frame_height=800,\n",
    "            title=imagedata[\"filename\"],\n",
    "            flip=False\n",
    "        )\n",
    "        # Save clicks to dictionary\n",
    "        imagedata[\"clicks_bkg\"] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert clicks to a tidy data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        \n",
    "        temp = imagedata[\"clicks_bkg\"].to_df()\n",
    "\n",
    "        # Add \"roi\" column (in this case there is just one ROI per sample with number \"0\")\n",
    "        temp[\"roi\"] = 0\n",
    "\n",
    "        # Save clicks to dictionary as tidy data frame (this will overwrite the previously saved version of the clicks!)\n",
    "        imagedata[\"clicks_bkg\"] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the bebi103.image.verts_to_roi function to convert the set of vertices (clicks) that define a polygon to a region of interest (the inside of the polygon):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        \n",
    "        dicts[k1_channel][k2_sample][\"rois_bkg\"] = [bebi103.image.verts_to_roi(imagedata[\"clicks_bkg\"][['x', 'y']].values, \n",
    "                                    imagedata[\"matrix_sum\"].shape[0], \n",
    "                                    imagedata[\"matrix_sum\"].shape[1])\n",
    "        for _, g in imagedata[\"clicks_bkg\"].groupby('roi')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the ROIs are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        \n",
    "        # The function above returned 3 representations of our ROI:\n",
    "        # roi = Boolean matrix (mask) in the size of my original image with \"True\" values where the ROI is\n",
    "        # roi_bbox = Bounding box around ROI\n",
    "        # roi_box = Boolean matrix in the size of the bounding box (roi_bbox) with \"True\" values where the ROI is\n",
    "        roi, roi_bbox, roi_box = imagedata[\"rois_bkg\"][0]\n",
    "\n",
    "        # Make grayscale image that is now RGB/CMY\n",
    "        im = np.dstack(3 * [skimage.img_as_float(imagedata[\"matrix_sum\"])])\n",
    "\n",
    "        # Max out first channel\n",
    "        im[roi, 0] = im.max()\n",
    "        plots.append(\n",
    "            bebi103.image.imshow(\n",
    "                im,\n",
    "                title=\"{}_bkg-area\".format(imagedata[\"filename\"]),\n",
    "                frame_height=250,\n",
    "                cmap=\"rgb\",\n",
    "                flip=False,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "# Look at the images\n",
    "bokeh.io.show(bokeh.layouts.gridplot(plots, ncols=3))\n",
    "        \n",
    "# Save first image (this assumes that all bkg areas are the same)\n",
    "bokeh.io.export_png(plots[0], \n",
    "           filename=\"{}/{}_bkg_area.png\".format(saving_dir, data_dir.split(\"/\")[-1]),\n",
    "           width=2400, height=2400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean and median fluorescence values in background area for each stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        \n",
    "        roi, roi_bbox, roi_box = imagedata[\"rois_bkg\"][0]\n",
    "        im = imagedata[\"matrix_orig\"]\n",
    "        \n",
    "        for stack in im:\n",
    "            # Calculate mean and median intensity inside bkg area for each individual stack\n",
    "            mean_int_bkg = stack[roi].mean()\n",
    "#             median_int_bkg = np.median(stack[roi])\n",
    "\n",
    "            # Append to dictionary\n",
    "            imagedata[\"mean_int_bkg\"].append(mean_int_bkg)\n",
    "#             imagedata[\"median_int_bkg\"].append(median_int_bkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute background normalized fluorescence values in each stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        \n",
    "        roi, roi_bbox, roi_box = imagedata[\"rois_bkg\"][0]\n",
    "        im = imagedata[\"matrix_orig\"]\n",
    "            \n",
    "        for i, stack in enumerate(im):\n",
    "            \n",
    "            # Get mean and median pixel values of ROI and bkg fo stack\n",
    "            int_mean = imagedata[\"mean_int\"][i]\n",
    "            bkg_mean = imagedata[\"mean_int_bkg\"][i]\n",
    "\n",
    "            # Compute BG substracted mean and median pixel values in ROI for each stack\n",
    "            norm_int_mean = int_mean - bkg_mean\n",
    "            if norm_int_mean < 0:\n",
    "                imagedata[\"mean_int_norm\"].append(0)\n",
    "            else: \n",
    "                imagedata[\"mean_int_norm\"].append(norm_int_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a data frame and csv file for comparison of pixel values across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for k1_channel, v1_sample in dicts.items():\n",
    "    for k2_sample, imagedata in v1_sample.items():\n",
    "        x = 1\n",
    "\n",
    "        for i, stack in enumerate(imagedata[\"matrix_orig\"]):\n",
    "            df = df.append(\n",
    "                {\"Filename\" : imagedata[\"filename\"],\n",
    "                 \"Channel\" : k1_channel,\n",
    "                 \"Sample\" : k2_sample,\n",
    "                 \"Time\": imagedata[\"time_points\"][i],\n",
    "                 \"Frame\": x,\n",
    "                 \"Channel + Sample\" : (k1_channel + \" (\" + k2_sample + \")\"),\n",
    "                 \"Mean pixel value in ROI\" : imagedata[\"mean_int\"][i],\n",
    "                 \"Mean pixel value in bkg area\" : imagedata[\"mean_int_bkg\"][i],\n",
    "                 \"Norm_mean_pixel_value_in_ROI\" : imagedata[\"mean_int_norm\"][i],\n",
    "                }, \n",
    "                ignore_index=True)\n",
    "            x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display top of data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot raw mean fluorescence values over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "for idx, sample in enumerate(np.unique(df[\"Channel + Sample\"].values)):\n",
    "    x = df[df[\"Channel + Sample\"]==sample][\"Time\"].values\n",
    "    y = df[df[\"Channel + Sample\"]==sample][\"Mean pixel value in ROI\"].values\n",
    "\n",
    "    ax.plot(x, y, c=cm.Set1(idx), label=sample)\n",
    "\n",
    "# Add stimulation bar\n",
    "for x1, x2 in zip(led_on, led_off):\n",
    "    ax.axvspan(x1, x2, alpha=0.25, color='red')\n",
    "\n",
    "# Set axis labels\n",
    "fontsize = 13\n",
    "fontweight = 'normal'\n",
    "fontproperties = {'weight':fontweight, 'size':fontsize}\n",
    "ax.set_xlabel('Time (s)', fontproperties)\n",
    "ax.set_ylabel('Relative Fluorescence Units', fontproperties)\n",
    "\n",
    "# Define figure title\n",
    "ax.set_title('Raw Mean Fluorescence', weight='normal', size=fontsize+5)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=fontsize)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(\"{}/{}_mean-fluorescence.png\".format(saving_dir, data_dir.split(\"/\")[-1]),\n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot bkg normalized mean fluorescence values over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "for idx, sample in enumerate(np.unique(df[\"Channel + Sample\"].values)):\n",
    "    x = df[df[\"Channel + Sample\"]==sample][\"Time\"].values\n",
    "    y = df[df[\"Channel + Sample\"]==sample][\"Norm_mean_pixel_value_in_ROI\"].values\n",
    "\n",
    "    ax.plot(x, y, c=cm.Set1(idx), label=sample)\n",
    "\n",
    "# Add stimulation bar\n",
    "for x1, x2 in zip(led_on, led_off):\n",
    "    ax.axvspan(x1, x2, alpha=0.25, color='red')\n",
    "\n",
    "# Set axis labels\n",
    "fontsize = 13\n",
    "fontweight = 'normal'\n",
    "fontproperties = {'weight':fontweight, 'size':fontsize}\n",
    "ax.set_xlabel('Time (s)', fontproperties)\n",
    "ax.set_ylabel('Relative Fluorescence Units', fontproperties)\n",
    "\n",
    "# Define figure title\n",
    "ax.set_title('Background Normalized Mean Fluorescence', weight='normal', size=fontsize+5)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=fontsize)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(\"{}/{}_bkg-norm-mean-fluorescence.png\".format(saving_dir, data_dir.split(\"/\")[-1]),\n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate $\\Delta / F_0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $F_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all rows where time < time point that LED turns on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f0 = df.query(\"`Time` < @led_on[0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean of bkg normalized pixel values inside ROI within first 5s and define as f0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = np.mean(df_f0[\"Norm_mean_pixel_value_in_ROI\"].values)\n",
    "f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column with $\\Delta F / F_0$ values to original data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['df/f0'] = (df.Norm_mean_pixel_value_in_ROI - f0) / f0         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot $\\Delta F / F_0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "for idx, sample in enumerate(np.unique(df[\"Channel + Sample\"].values)):\n",
    "    x = df[df[\"Channel + Sample\"]==sample][\"Time\"].values\n",
    "    y = df[df[\"Channel + Sample\"]==sample][\"df/f0\"].values\n",
    "\n",
    "    ax.plot(x, y, c=cm.Set1(idx), label=sample)\n",
    "\n",
    "# Add stimulation bar\n",
    "for x1, x2 in zip(led_on, led_off):\n",
    "    ax.axvspan(x1, x2, alpha=0.25, color='red')\n",
    "\n",
    "# Set axis labels\n",
    "fontsize = 13\n",
    "fontweight = 'normal'\n",
    "fontproperties = {'weight':fontweight, 'size':fontsize}\n",
    "ax.set_xlabel('Time (s)', fontproperties)\n",
    "ax.set_ylabel('$\\Delta F / F_0$', fontproperties)\n",
    "\n",
    "# Define figure title\n",
    "ax.set_title('$\\Delta F / F_0$', weight='normal', size=fontsize+5)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=fontsize)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(\"{}/{}_df-f0.png\".format(saving_dir, data_dir.split(\"/\")[-1]),\n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add LED column to data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column called \"LED\" to dataframe filled with 0s\n",
    "df[\"LED\"] = 0\n",
    "\n",
    "for idx, timepoint in enumerate(df[\"Time\"].values):\n",
    "    for i, value in enumerate(led_on):\n",
    "        if timepoint >= led_on[i] and timepoint < led_off[i]:\n",
    "            df[\"LED\"][idx] = 1     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data frame to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"{}/{}_2-photon_fluorescence_analysis.csv\".format(saving_dir, data_dir.split(\"/\")[-1]), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle dictionary containing images and clicks for later use\n",
    "This dictionary contains the original iamge stacks, sum fluorescence images, names of the images, clicks as data frame, rois and the sum of the pixel intensity values inside the roi for each individual stack.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (\"{}\").format(saving_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pickle to save dictionaries\n",
    "\n",
    "# The advantage of HIGHEST_PROTOCOL is that files get smaller. This makes unpickling sometimes much faster.\n",
    "with open(\n",
    "    (\"{}/{}_2-photon_fluorescence_analysis.pickle\").format(path, data_dir.split(\"/\")[-1]),\n",
    "    \"wb\",\n",
    ") as handle:\n",
    "    pickle.dump(dicts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of pixels (assuming square image)\n",
    "pixels = len(imagedata[\"matrix_orig\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find mean pixel value in backgrgound area for each frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make another image stack where each image is of size 512,512 and filled with the average value on the background ROI for that frame\n",
    "MEAN = [np.ones((pixels, pixels))*i for i in imagedata[\"mean_int_bkg\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is our original z-stack\n",
    "X = np.array(imagedata[\"matrix_orig\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the z-stack where each pixel value is subtracted by the mean pixel value in the background\n",
    "Y = X-MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all values that became < 0 during the background subtraction = 0\n",
    "Y[Y<0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find frames before LED turns on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define F0 as mean value of each pixel in frames 0 - five frames before LED turns on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(led_on) == 1: # LED turns on only once\n",
    "    frame_on = np.array(np.argwhere(imagedata[\"time_points\"]<led_on).reshape(-1))[-5]\n",
    "\n",
    "else: # LED turns on more than once\n",
    "    frame_on = np.array(np.argwhere(imagedata[\"time_points\"]<led_on[0]).reshape(-1))[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F0 = Y[0:frame_on,:,:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate df/f0 z-stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx = (Y-F0)/F0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the two cells below to apply the ROI mask drawn above to see only this ROI in the heat map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create array containing z copies of mask to match shape of Y\n",
    "# mask = []\n",
    "\n",
    "# for i in np.arange(len(Y)):\n",
    "#     mask.append(imagedata[\"roi_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtx[~np.array(mask)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot sum projection of heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "im = plt.imshow(mtx.sum(axis=0), origin='lower', cmap=\"gray\")\n",
    "\n",
    "#Set zoom\n",
    "ax.set_xlim((0,pixels))\n",
    "ax.set_ylim((0,pixels))\n",
    "\n",
    "fontsize = 13\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Pixel (x)', fontsize=fontsize)\n",
    "ax.set_ylabel('Pixel (y)', fontsize=fontsize)\n",
    "\n",
    "# Add heatmap legend\n",
    "plt.colorbar(shrink=0.5).set_label('sum projection of $\\Delta F / F_0$', fontsize=fontsize)\n",
    "\n",
    "ax.set_title(\"$\\Delta F / F_0$\", weight='bold', fontsize=fontsize+5)\n",
    "\n",
    "plt.savefig(\"{}/{}_df-f0_heatmap.png\".format(saving_dir, data_dir.split(\"/\")[-1]),\n",
    "            bbox_inches='tight', \n",
    "            dpi=300)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot animated heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "a = mtx\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "frame = 0\n",
    "idx = 0\n",
    "\n",
    "# # For normalization of heatmap between thresholds:\n",
    "# norm = matplotlib.colors.Normalize(vmin = 0, vmax = 2000, clip = False)\n",
    "# im = plt.imshow(a[frame], origin='lower', cmap=\"hot\", norm=norm)\n",
    "\n",
    "im = plt.imshow(a[frame], origin='lower', cmap=\"gray\")\n",
    "\n",
    "# Set zoom\n",
    "# ax.set_xlim((150,400))\n",
    "# ax.set_ylim((150,400))\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_xlabel('Pixel (x)')\n",
    "ax.set_ylabel('Pixel (y)')\n",
    "\n",
    "# Define figure title\n",
    "# ax.set_title('$\\Delta F / F_0$', weight='bold')\n",
    "\n",
    "# Add heatmap legend\n",
    "plt.colorbar(shrink=0.5).set_label('$\\Delta F / F_0$')\n",
    "\n",
    "# Define elapsed time text\n",
    "time_text = ax.text(0.02, 0.95, '', transform=ax.transAxes, color='white')\n",
    "\n",
    "# Define size,location and color of circle showing stimulation\n",
    "circle = plt.Circle((0.9, 0.9), 0.05, color='r', transform=ax.transAxes)\n",
    "circle_status = False\n",
    "\n",
    "# # Define polygon to show ROI\n",
    "# points = rois_for_polygon[0].drop(['roi'], axis=1).values\n",
    "# polygon = plt.Polygon(points, fill=None, edgecolor='white', linestyle=(0, (1,10)), linewidth=0.25)\n",
    "\n",
    "def update(*args):\n",
    "    global frame\n",
    "    global idx \n",
    "    global circle_status\n",
    "\n",
    "    im.set_array(a[frame])\n",
    "    \n",
    "    # Define when stimulation circle appears\n",
    "    if df[\"LED\"].values[idx] == 1:\n",
    "        if circle_status == False:\n",
    "            ax.add_artist(circle)\n",
    "            circle_status = True\n",
    "            print(\"Turned ON\")\n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "    elif df[\"LED\"].values[idx] == 0:\n",
    "        if circle_status == False:\n",
    "            pass\n",
    "        else:\n",
    "            circle.set_visible(False)\n",
    "            print(\"Turned OFF\")\n",
    "            circle_status = False\n",
    "\n",
    "    frame += 1\n",
    "    frame %= len(a)\n",
    "    \n",
    "    time_text.set_text('Time in s: %.1f' % df[\"Time\"].values[idx])\n",
    "    idx += 1\n",
    "        \n",
    "    return im\n",
    "\n",
    "# For display:\n",
    "ani = animation.FuncAnimation(fig, update, interval=50)\n",
    "\n",
    "# # For saving:\n",
    "# ani = animation.FuncAnimation(fig, update, interval=200, save_count=len(a))\n",
    "\n",
    "# # Set up formatting for saving\n",
    "# Writer = animation.writers['ffmpeg']\n",
    "# writer = Writer(fps=5, metadata=dict(artist='Me'), bitrate=1800)\n",
    "# ani.save(\"{}/{}_df-f0_heatmap_movie.mp4\".format(saving_dir, data_dir.split(\"/\")[-1]), writer=writer)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,skimage,bokeh,bebi103,jupyterlab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
